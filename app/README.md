# Android App (PocketLoRA)

This folder contains the **Android application source code** for PocketLoRA.

---

## Structure

app/
â”‚
â”œâ”€â”€ src/ # Main application source
â”‚ â”œâ”€â”€ main/
â”‚ â”‚ â”œâ”€â”€ java/com/pocketlora/ # Kotlin/Jetpack Compose code
â”‚ â”‚ â”‚ â”œâ”€â”€ ui/ # UI screens (training, adapters, inference)
â”‚ â”‚ â”‚ â”œâ”€â”€ manager/ # Adapter lifecycle & storage manager
â”‚ â”‚ â”‚ â”œâ”€â”€ scheduler/ # Thermal & power-aware scheduler
â”‚ â”‚ â”‚ â””â”€â”€ inference/ # Runtime integration (ExecuTorch/ONNX)
â”‚ â”‚ â””â”€â”€ res/ # Layouts, drawables, themes
â”‚ â”‚
â”‚ â”œâ”€â”€ androidTest/ # Instrumentation tests
â”‚ â””â”€â”€ test/ # Unit tests
â”‚
â”œâ”€â”€ build.gradle # Gradle build config for the app
â”œâ”€â”€ settings.gradle # Project-level Gradle settings
â””â”€â”€ AndroidManifest.xml # App permissions, entry points, intents



---

## Key Components

- **UI (Jetpack Compose)**  
  Screens for:
  - Training progress  
  - Adapter selection & management  
  - Inference chat window  

- **Adapter Manager**  
  Handles loading, attaching, and exporting adapters.

- **Scheduler**  
  Ensures training only runs under safe conditions (charging, Wi-Fi, screen off).

- **Inference Runtime**  
  Connects with ExecuTorch / ONNX Runtime Mobile for LLM inference.

---

## Build Instructions

1. Open this folder in **Android Studio**.  
2. Sync Gradle dependencies.  
3. Build and install:  
   ```bash
   ./gradlew assembleDebug
   adb install build/outputs/apk/debug/app-debug.apk





# ğŸ“± PocketLoRA â€“ On-Device Fine-Tuning for Billion+ Parameter LLMs

PocketLoRA is a lightweight framework that enables **on-device fine-tuning** of billion+ parameter Large Language Models (LLMs) on smartphones (Galaxy S23â€“S25 class).  
It allows users to adapt pre-trained LLMs to their **personal data** with **low-power training**, **hot-swappable adapters**, and **strict on-device privacy**.

---

## ğŸš© Problem Statement

Traditional LLM fine-tuning requires **expensive GPUs** and **cloud infrastructure**.  
Users cannot personalize models without exposing sensitive data to servers.  

**Challenge:** How can we enable **efficient fine-tuning of billion+ parameter LLMs** directly on smartphones, within **tight compute, memory, and power budgets**?

---

## ğŸ’¡ Our Solution

PocketLoRA introduces an **efficient, privacy-preserving on-device fine-tuning framework**:

- **LoRA/QLoRA adapters** â†’ train only a few million parameters, not the full model.  
- **NF4 quantization** â†’ compresses models for mobile memory budgets.  
- **Thermal & power-aware scheduler** â†’ trains only under safe conditions.  
- **Hot-swap adapters** â†’ instantly enable/disable task-specific adapters.  
- **ExecuTorch / ONNX Mobile runtime** â†’ optimized inference on-device.  

---

## ğŸŒŸ Features

- ğŸ”‹ **Low-Power Fine-Tuning** â†’ runs safely under charging/Wi-Fi/cool temperature  
- ğŸ”Œ **Hot-Swap Adapters** â†’ small files, enable/disable at runtime  
- ğŸ”’ **Privacy by Design** â†’ all training is fully on-device  
- âš¡ **Optimized Runtime** â†’ fast inference with ExecuTorch / ONNX  
- ğŸ“± **User-Friendly UI** â†’ training, adapter management, and inference screens  

See full [features.md](docs/features.md).

---

## ğŸ› ï¸ Tech Stack

- **Frameworks**: PyTorch, Hugging Face Transformers, PEFT, bitsandbytes  
- **Quantization**: NF4 / QLoRA  
- **Runtime**: ExecuTorch / ONNX Runtime Mobile  
- **App**: Kotlin, Jetpack Compose, Android Studio  
- **Scheduling**: Power & thermal-aware background job manager  

See [technical_stack.md](docs/technical_stack.md).

---

## ğŸ“‚ Repository Structure

app/ # Android app (UI, adapter manager, inference)
tools/ # Python training scripts (LoRA/quantization)
models/ # Base quantized model (ignored in Git)
adapters/ # Trained LoRA adapters
docs/ # Technical documentation & diagrams
images/ # UI screenshots and diagrams



---

## âš¡ Quickstart

### 1. Clone Repo
```bash
git clone https://github.com/<your-username>/pocketlora.git
cd pocketlora

2. Python Environment (training tools)
python3 -m venv .venv
source .venv/bin/activate
pip install -r tools/requirements.txt
3. Build Android App
cd app
./gradlew assembleDebug
adb install build/outputs/apk/debug/app-debug.apk
4. Add Models & Adapters
Place quantized model in models/ (not tracked by Git)
Place/collect trained adapters in adapters/
5. Run App
Select dataset â†’ Train adapter â†’ Manage in Adapters screen â†’ Run inference
ğŸ“¸ Screenshots
Training	Adapters	Inference
ğŸ“œ License
This project is licensed under the MIT License